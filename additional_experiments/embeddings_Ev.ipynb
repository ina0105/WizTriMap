{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import trimap\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR100\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Config \n",
    "DATASETS = [\"CIFAR100\", \"MNIST\", \"FashionMNIST\"]\n",
    "METHODS_2D = [\"TriMap\", \"UMAP\", \"t-SNE\", \"PCA\"]\n",
    "OUTPUT_DIR = \"saved_embeddings\"\n",
    "NDIMS = 2  \n",
    "\n",
    "# Dataset Loader \n",
    "def load_dataset(name):\n",
    "    transform = transforms.ToTensor()\n",
    "    if name == \"MNIST\":\n",
    "        dataset = MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "        X = torch.stack([img[0].squeeze() for img in dataset])\n",
    "    elif name == \"FashionMNIST\":\n",
    "        dataset = FashionMNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "        X = torch.stack([img[0].squeeze() for img in dataset])\n",
    "    elif name == \"CIFAR100\":\n",
    "        dataset = CIFAR100(\"./data\", train=True, download=True, transform=transform)\n",
    "        X = torch.stack([img[0] for img in dataset])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset name\")\n",
    "    X_flat = X.view(X.size(0), -1).numpy()\n",
    "    return X_flat\n",
    "\n",
    "# Projection Function \n",
    "def project(method, X_flat, dim):\n",
    "    if method == \"TriMap\":\n",
    "        return trimap.TRIMAP(n_dims=dim).fit_transform(X_flat)\n",
    "    elif method == \"UMAP\":\n",
    "        return umap.UMAP(n_components=dim).fit_transform(X_flat)\n",
    "    elif method == \"t-SNE\":\n",
    "        return TSNE(n_components=dim).fit_transform(X_flat)\n",
    "    elif method == \"PCA\":\n",
    "        return PCA(n_components=dim).fit_transform(X_flat)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "#save\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "TRIMAP_DIMS = list(range(2, NDIMS + 1))\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    print(f\"\\nLoading dataset: {dataset}\")\n",
    "    X_flat = load_dataset(dataset)\n",
    "\n",
    "    for method in METHODS_2D:\n",
    "        dims = TRIMAP_DIMS if method == \"TriMap\" else [2]\n",
    "\n",
    "        for dim in dims:\n",
    "            print(f\"Projecting {dataset} using {method} ({dim}D)\")\n",
    "            emb = project(method, X_flat, dim)\n",
    "            file_path = os.path.join(OUTPUT_DIR, f\"{dataset}_{method}_{dim}D_embeddings.npy\")\n",
    "            np.save(file_path, emb)\n",
    "            print(f\"[Saved] {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import trustworthiness\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR100\n",
    "from torchvision import transforms\n",
    "import json\n",
    "\n",
    "# Settings \n",
    "TARGET_DATASET = \"FashionMNIST\"  # or \"MNIST\", \"CIFAR100\"\n",
    "TARGET_METRIC = \"silhouette\"  # silhouette, knn , pearson\n",
    "METHODS = [\"TriMap\", \"UMAP\", \"t-SNE\", \"PCA\"]\n",
    "EMBED_DIR = \"saved_embeddings\"\n",
    "K_NEIGHBORS = 10\n",
    "\n",
    "# Dataset Loader \n",
    "def load_dataset(name):\n",
    "    transform = transforms.ToTensor()\n",
    "    if name == \"MNIST\":\n",
    "        ds = MNIST(root=\"data\", train=True, download=False, transform=transform)\n",
    "    elif name == \"FashionMNIST\":\n",
    "        ds = FashionMNIST(root=\"data\", train=True, download=False, transform=transform)\n",
    "    elif name == \"CIFAR100\":\n",
    "        ds = CIFAR100(root=\"data\", train=True, download=False, transform=transform)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset\")\n",
    "    X = torch.stack([x[0].squeeze() for x in ds])\n",
    "    y = np.array([x[1] for x in ds])\n",
    "    X_flat = X.view(X.size(0), -1).numpy()\n",
    "    return X_flat, y\n",
    "\n",
    "\n",
    "# Convert NumPy types for JSON \n",
    "def convert_numpy_types(d):\n",
    "    out = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, (np.float32, np.float64)):\n",
    "            out[k] = float(v)\n",
    "        elif isinstance(v, (np.int32, np.int64)):\n",
    "            out[k] = int(v)\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "# Main Loop \n",
    "print(f\"\\nLoading dataset: {TARGET_DATASET}\")\n",
    "X_orig, labels = load_dataset(TARGET_DATASET)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for method in METHODS:\n",
    "    key = f\"{TARGET_DATASET}_{method}_2D\"\n",
    "    emb_file = os.path.join(EMBED_DIR, f\"{key}_embeddings.npy\")\n",
    "    if not os.path.exists(emb_file):\n",
    "        print(f\"[Missing] {emb_file}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Evaluating {TARGET_METRIC} on {key}\")\n",
    "    X_emb = np.load(emb_file)\n",
    "\n",
    "    try:\n",
    "        if TARGET_METRIC == \"silhouette\":\n",
    "            metric_val = silhouette_score(X_emb, labels)\n",
    "\n",
    "        elif TARGET_METRIC == \"knn\":\n",
    "            idx = np.random.permutation(len(labels))\n",
    "            train_idx, test_idx = idx[:int(0.8 * len(idx))], idx[int(0.8 * len(idx)):]\n",
    "            knn = KNeighborsClassifier(n_neighbors=K_NEIGHBORS).fit(X_emb[train_idx], labels[train_idx])\n",
    "            metric_val = knn.score(X_emb[test_idx], labels[test_idx])\n",
    "\n",
    "        elif TARGET_METRIC == \"pearson\":\n",
    "            idx = np.random.choice(len(X_orig), 2000, replace=False)\n",
    "            D_high = squareform(pdist(X_orig[idx]))\n",
    "            D_low = squareform(pdist(X_emb[idx]))\n",
    "            flat_high = D_high.ravel()\n",
    "            flat_low = D_low.ravel()\n",
    "            metric_val = np.corrcoef(flat_high, flat_low)[0, 1]\n",
    "            if np.isnan(metric_val):\n",
    "                metric_val = 0.0\n",
    "        else:\n",
    "            raise ValueError(\"Invalid metric\")\n",
    "\n",
    "        results[key] = convert_numpy_types({TARGET_METRIC: metric_val})\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing {TARGET_METRIC} for {key}: {e}\")\n",
    "\n",
    "# Save results \n",
    "out_file = f\"{TARGET_DATASET}_{TARGET_METRIC}_results.json\"\n",
    "with open(out_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"\\nSaved {TARGET_METRIC} results to {out_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
